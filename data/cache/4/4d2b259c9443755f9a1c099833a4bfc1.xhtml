
<h1 class="sectionedit1" id="spatial_modelling_of_bumblebees_butterflies_in_southern_norway">Spatial modelling of bumblebees &amp; butterflies in Southern Norway</h1>
<div class="level1">

<p>
<strong>Jens Åström, Department of Ecology, SLU, SWEDEN</strong>
<br/>

</p>
<ul>
<li class="level1"><div class="li"> Download the project proposal <a href="http://www.spatial-ecology.net/ost4sem/project/unidk2010/MODB&amp;B/documents/Jens.pdf" class="urlextern" target="blanc" title="http://www.spatial-ecology.net/ost4sem/project/unidk2010/MODB&amp;B/documents/Jens.pdf" rel="nofollow noopener"> Jens.pdf </a>.</div>
</li>
</ul>

<p>
<br/>

</p>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;Spatial modelling of bumblebees &amp; butterflies in Southern Norway&quot;,&quot;hid&quot;:&quot;spatial_modelling_of_bumblebees_butterflies_in_southern_norway&quot;,&quot;codeblockOffset&quot;:0,&quot;secid&quot;:1,&quot;range&quot;:&quot;1-273&quot;} -->
<h2 class="sectionedit2" id="introduction">INTRODUCTION</h2>
<div class="level2">

<p>
<strong>I work together with Thijs, see <a href="/dokuwiki/doku.php?id=wikidk:dk10marine" class="wikilink1" title="wikidk:dk10marine"> MARINE   </a>. We use basically the same workflow and methods, but with different data sets.</strong>
</p>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;INTRODUCTION&quot;,&quot;hid&quot;:&quot;introduction&quot;,&quot;codeblockOffset&quot;:0,&quot;secid&quot;:2,&quot;range&quot;:&quot;274-444&quot;} -->
<h3 class="sectionedit3" id="general_framework_of_this_analysis">General framework of this analysis</h3>
<div class="level3">

<p>
Model the abundance and species richness of bumblebees and butterflies as explained by environmental and spatial characteristics. Explanatory variables exists both in GIS layers and Excel sheets filled in by those who conducted the study. The data was kindly made available to me by the project managers at Norwegian Institute for Nature Research, NINA. 
</p>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;General framework of this analysis&quot;,&quot;hid&quot;:&quot;general_framework_of_this_analysis&quot;,&quot;codeblockOffset&quot;:0,&quot;secid&quot;:3,&quot;range&quot;:&quot;445-845&quot;} -->
<h3 class="sectionedit4" id="project_objectives">Project objectives</h3>
<div class="level3">

<p>
It is commonplace in the ecology to try and explain abundances and diversity patterns from a limited number of predictive variables observed in the field. Often, this is done just to understand the importance of these predictive variables, and not primarily to predict flora and fauna communities in new areas and points in time. Some times the predictive variables are the direct result of manipulations by the researcher. The analyses often stop after having tested if the parameters are different from zero, but hopefully they also contain estimations of effect size. How well your models represent the world can be checked by looking at how much variation in the data they explain. However, sometimes these measures are difficult to interpret directly. Secondly, there might exist other explaining factors i GIS layers that might help explain the results of your experiment / inventory. 
</p>
<ul>
<li class="level1 node"><div class="li">I will attempt to visualize some of the uncertainty in the models. The idea is this:</div>
<ul>
<li class="level2"><div class="li">If the world works as your model says it does, what will the world look like on average?<ul>
<li class="level1"><div class="li"> What will the world look like any given day?</div>
</li>
<li class="level3"><div class="li"> What will the world look like if it behaves a little differently every day? IN OTHER WORDS: What will the world look like if you are not a hundred percent certain of your model estimates?</div>
</li>
</ul>
<ol>
<li class="level3"><div class="li"> I will practice the art of extracting predictor variables from GIS layers.</div>
</li>
</ol>
<ul>
<li class="level3"><div class="li"> This will be done by matching the GIS layers with the inventoried coordinates and extracting the corresponding information.</div>
</li>
</ul>
</div>
</li>
</ul>
</li>
</ul>

<p>
The modelling will be quite coarse since I only have a few explanatory variables. The uncertainty of the predictions will likely be high. This is not an exercise in building a good ecological model, just to practice using the tools.
</p>

<p>
My aim is to automate the work as much as possible using scripts. 
</p>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;Project objectives&quot;,&quot;hid&quot;:&quot;project_objectives&quot;,&quot;codeblockOffset&quot;:0,&quot;secid&quot;:4,&quot;range&quot;:&quot;846-2718&quot;} -->
<h2 class="sectionedit5" id="metadata">METADATA</h2>
<div class="level2">

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;METADATA&quot;,&quot;hid&quot;:&quot;metadata&quot;,&quot;codeblockOffset&quot;:0,&quot;secid&quot;:5,&quot;range&quot;:&quot;2719-2739&quot;} -->
<h3 class="sectionedit6" id="raster_data">Raster data</h3>
<div class="level3">

<p>
Dowloaded Elevation maps in 30 meter resolution. This comes in EPSG:4326 projection.
</p>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;Raster data&quot;,&quot;hid&quot;:&quot;raster_data&quot;,&quot;codeblockOffset&quot;:0,&quot;secid&quot;:6,&quot;range&quot;:&quot;2740-2846&quot;} -->
<h3 class="sectionedit7" id="vector_data">Vector Data</h3>
<div class="level3">

<p>
Shape files split into different tiles. Contains elevation lines, land cover and a few other possibly usable layers. Together, I have 453 shape file that I want to import. (I use a loop)
The data has projection EPSG:32632.
</p>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;Vector Data&quot;,&quot;hid&quot;:&quot;vector_data&quot;,&quot;codeblockOffset&quot;:0,&quot;secid&quot;:7,&quot;range&quot;:&quot;2847-3092&quot;} -->
<h3 class="sectionedit8" id="text_files_and_tables">Text files and tables</h3>
<div class="level3">

<p>
Two text files of bumblebee and butterfly data with approx 1000 lines each. One other txt file with transect ID and X Y positions in appropriate UTM scale.
</p>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;Text files and tables&quot;,&quot;hid&quot;:&quot;text_files_and_tables&quot;,&quot;codeblockOffset&quot;:0,&quot;secid&quot;:8,&quot;range&quot;:&quot;3093-3281&quot;} -->
<h3 class="sectionedit9" id="ortophoto">Ortophoto</h3>
<div class="level3">

<p>
No orthophoto
<br/>

</p>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;Ortophoto&quot;,&quot;hid&quot;:&quot;ortophoto&quot;,&quot;codeblockOffset&quot;:0,&quot;secid&quot;:9,&quot;range&quot;:&quot;3282-3319&quot;} -->
<h2 class="sectionedit10" id="method">METHOD</h2>
<div class="level2">

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;METHOD&quot;,&quot;hid&quot;:&quot;method&quot;,&quot;codeblockOffset&quot;:0,&quot;secid&quot;:10,&quot;range&quot;:&quot;3320-3338&quot;} -->
<h3 class="sectionedit11" id="workflow">WORKFLOW</h3>
<div class="level3">
<ul>
<li class="level1"><div class="li"> Compile Inventory data in R</div>
</li>
<li class="level1 node"><div class="li"> Import GIS files in GRASS</div>
<ul>
<li class="level2"><div class="li"> Automate this because there are many shape files</div>
</li>
<li class="level2"><div class="li"> Create new vector point map of inventoried sites</div>
</li>
</ul>
</li>
<li class="level1 node"><div class="li"> Merge regions in GRASS to combined layer</div>
<ul>
<li class="level2"><div class="li"> Create new mapset “Combined”</div>
</li>
<li class="level2"><div class="li"> Patch the different regions together</div>
</li>
</ul>
</li>
<li class="level1 node"><div class="li"> Extract explanatory data from GRASS at sampled locations</div>
<ul>
<li class="level2"><div class="li"> Match inventory vector points with values in other layers </div>
</li>
</ul>
</li>
<li class="level1 node"><div class="li"> Export the explanatory variables to R</div>
<ul>
<li class="level2"><div class="li"> Use the spgrass6 package</div>
</li>
</ul>
</li>
<li class="level1 node"><div class="li"> Model the species richness and abundance</div>
<ul>
<li class="level2"><div class="li"> Do a simple GLM</div>
</li>
<li class="level2"><div class="li"> Mimic the GLM in BUGS language to get (proper?) variation in parameter estimates</div>
</li>
</ul>
</li>
<li class="level1 node"><div class="li"> Predict to new areas</div>
<ul>
<li class="level2"><div class="li"> Predict the best estimates from both models</div>
</li>
<li class="level2"><div class="li"> Predict realized outcome of best estimate (What you can observe any given day)</div>
</li>
<li class="level2"><div class="li"> Predict realized outcomes from a set of models, with parameter estimates varying according to the uncertainty in your knowledge of the parameters.</div>
</li>
</ul>
</li>
<li class="level1 node"><div class="li"> Plot the predictions</div>
<ul>
<li class="level2"><div class="li"> Make output pictures</div>
</li>
<li class="level2"><div class="li"> Make movies of the combination of several possible outcomes.</div>
</li>
</ul>
</li>
</ul>

<p>
<br/>

</p>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;WORKFLOW&quot;,&quot;hid&quot;:&quot;workflow&quot;,&quot;codeblockOffset&quot;:0,&quot;secid&quot;:11,&quot;range&quot;:&quot;3339-4441&quot;} -->
<h2 class="sectionedit12" id="data_import_and_processing">DATA IMPORT and Processing</h2>
<div class="level2">

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;DATA IMPORT and Processing&quot;,&quot;hid&quot;:&quot;data_import_and_processing&quot;,&quot;codeblockOffset&quot;:0,&quot;secid&quot;:12,&quot;range&quot;:&quot;4442-4480&quot;} -->
<h3 class="sectionedit13" id="grass">GRASS</h3>
<div class="level3">
<pre class="code bash"><span class="co0">##########################################################################</span>
<span class="co0">#!/bin/bash</span>
&nbsp;
<span class="co0">#</span>
<span class="co0">#</span>
<span class="co0">#	This is a bash file to import all of the shape files in the Norge data set.</span>
<span class="co0">#	The files are located in a tree, one branch looks like this:</span>
<span class="co0">#	/home/astrom/Ndata/07_Vestfold/0728_Lardal/UTM32_Euref89/Shape/728_AdminOmrader_lin.shp</span>
<span class="co0">#</span>
<span class="co0">#	This means I have to travel down each branch of the tree before I can import the files one by one.</span>
<span class="co0">#	Grass does not like numbers in the beginning of layer names so that means I cannot just use the input name as output name.</span>
<span class="co0">#</span>
<span class="co0">#	Therefore I use grep to extract certain parts of the file name and build up a new one. The numbers in the file name correspond to the area </span>
<span class="co0">#	so I have to replace the numbers with the corresponding name. Change the leading &quot;~/Ndata/*/*/&quot; and the &quot;ls */*/*.shp&quot; to suit your needs.</span>
<span class="co0">#</span>
<span class="co0">#	Author: Jens Åström 2010-07-02</span>
<span class="co0">#</span>
&nbsp;
&nbsp;
<span class="kw1">for</span> path <span class="kw1">in</span> <span class="sy0">`</span><span class="kw2">ls</span> <span class="re5">-d</span> ~<span class="sy0">/</span>Ndata<span class="sy0">/*/*/`</span> 
  <span class="kw1">do</span> 
   <span class="re2">base</span>=<span class="sy0">`</span><span class="kw2">basename</span> <span class="re1">$path</span><span class="sy0">`</span>
   <span class="re2">newname</span>=<span class="sy0">`</span><span class="kw3">echo</span> <span class="re1">$base</span> <span class="sy0">|</span><span class="kw2">grep</span> <span class="re5">-o</span> <span class="st_h">'[a-zA-Z]*'</span><span class="sy0">`</span>
   <span class="kw3">cd</span> <span class="re1">$path</span>
    <span class="kw1">for</span> <span class="kw2">file</span> <span class="kw1">in</span> <span class="sy0">`</span><span class="kw2">ls</span> <span class="sy0">*/*/*</span>.shp<span class="sy0">`</span> 
      <span class="kw1">do</span> 
      <span class="re2">filebase</span>=<span class="sy0">`</span><span class="kw2">basename</span> <span class="re1">$file</span> <span class="sy0">|</span> <span class="kw2">grep</span> <span class="re5">-o</span> <span class="st_h">'_[a-zA-Z]*_[a-zA-Z]*'</span><span class="sy0">`</span>
      <span class="re2">infile</span>=<span class="re1">$path</span><span class="re1">$file</span>
      <span class="co0">#echo $newname</span>
      <span class="co0">#echo $filebase</span>
      <span class="re2">outfile</span>=<span class="re1">$newname</span><span class="re1">$filebase</span>
      <span class="co0">#echo $outfile</span>
      <span class="co0">#echo $file</span>
      v.in.ogr <span class="re2">dsn</span>=<span class="re1">$file</span> <span class="re2">out</span>=<span class="re1">$outfile</span>
&nbsp;
    <span class="kw1">done</span>
  <span class="kw1">done</span>
&nbsp;
<span class="co0">#########################################################################</span>
&nbsp;
<span class="co0">#########################################################################</span>
<span class="co0">#!/bin/bash</span>
&nbsp;
<span class="co0">#</span>
<span class="co0">#	This script merges the layers from different regions into one (for each type of layer) and places the new layers in the mapset &quot;Combined&quot;</span>
<span class="co0">#	In total, there is 455 vector layers that are to be combined into 15</span>
<span class="co0">#	Some of these layers represent region boundaries so they will be deleted later</span>
<span class="co0">#</span>
<span class="co0">#</span>
<span class="co0">#	Author:Jens Åström 2010-07-04</span>
<span class="co0">#</span>
<span class="co0">#	</span>
&nbsp;
&nbsp;
g.mapset <span class="re5">-c</span> Combined <span class="co0">##create a new mapset</span>
<span class="co0">#g.mapset PERMANENT ##move back to the permanent mapset where all the different regions are located.</span>
&nbsp;
&nbsp;
&nbsp;
<span class="re2">out</span>=<span class="sy0">`</span><span class="kw2">ls</span> ~<span class="sy0">/</span>grassdata<span class="sy0">/</span>Norge<span class="sy0">/</span>PERMANENT<span class="sy0">/</span>vector<span class="sy0">/</span> <span class="sy0">|</span><span class="kw2">grep</span> <span class="re5">-E</span> <span class="re5">-o</span> <span class="st_h">'[a-zA-Z]*_[a-z]{3}$'</span> <span class="sy0">|</span><span class="kw2">sort</span> <span class="sy0">|</span><span class="kw2">uniq</span> <span class="sy0">|</span><span class="kw2">grep</span> <span class="re5">-v</span> <span class="st_h">'transects_pnt'</span><span class="sy0">`</span> 
<span class="kw1">for</span> <span class="br0">&#40;</span><span class="br0">&#40;</span><span class="re2">i</span>=<span class="nu0">1</span>;i<span class="sy0">&lt;</span>=<span class="sy0">`</span><span class="kw3">echo</span> <span class="re1">$out</span> <span class="sy0">|</span><span class="kw2">wc</span> -w<span class="sy0">`</span>;i++<span class="br0">&#41;</span><span class="br0">&#41;</span> ;<span class="kw1">do</span>
<span class="re2">out_now</span>=<span class="sy0">`</span><span class="kw3">echo</span> <span class="re1">$out</span> <span class="sy0">|</span> <span class="kw2">awk</span> <span class="st_h">'{print $'</span><span class="re1">$i</span><span class="st_h">'}'</span><span class="sy0">`</span>
<span class="co0">#echo $out_now</span>
<span class="re2">string</span>=<span class="st0">&quot;ls ~/grassdata/Norge/PERMANENT/vector/ |grep <span class="es5">`echo $out_now`</span>&quot;</span> 
<span class="re2">temp</span>=<span class="sy0">`</span><span class="kw3">eval</span> <span class="re1">$string</span><span class="sy0">`</span>
<span class="re2">in_temp</span>=<span class="sy0">`</span><span class="kw3">echo</span> <span class="re1">$temp</span> <span class="sy0">|</span><span class="kw2">sed</span> <span class="st0">&quot;s/ /@PERMANENT,/g&quot;</span><span class="sy0">`</span>
<span class="re2">in</span>=<span class="re1">$in_temp</span><span class="sy0">@</span>PERMANENT
<span class="co0">#echo $in</span>
v.patch <span class="re2">input</span>=<span class="re1">$in</span> <span class="re2">output</span>=<span class="re1">$out_now</span> <span class="re5">-e</span> <span class="re5">--overwrite</span>
<span class="kw1">done</span>
&nbsp;
<span class="co0">#	This generates following warnings!</span>
<span class="co0">#</span>
<span class="co0">##	Intersections at borders will have to be snapped</span>
<span class="co0">##	Lines common between files will have to be edited</span>
<span class="co0">##	The header information also may have to be edited</span>
<span class="co0">#</span>
<span class="co0">#</span>
<span class="co0">#</span>
&nbsp;
&nbsp;
<span class="co0">############################################################################</span>
&nbsp;
<span class="co0">############################################################################</span>
<span class="co0">#!/bin/bash</span>
<span class="co0">#</span>
<span class="co0">#</span>
<span class="co0">#	This script changes the Projection of the downloaded elevation map from EPSG:4326 to that of the Norway data, EPSG:25832 and combines the into one big tile</span>
<span class="co0">#</span>
<span class="co0">#	Then it imports this big tif in GRASS, and makes a &quot;cut&quot; at the extent of my other data. No point having a larger elevation map than the rest of the data.</span>
<span class="co0">#       </span>
<span class="co0">#	Finally, it copies the new raster to the mapset Combined, where all the combined tiles are</span>
<span class="co0">#</span>
<span class="co0">#</span>
<span class="kw3">cd</span> ~<span class="sy0">/</span>Ndata <span class="co0">#this is where I want the output file</span>
<span class="kw2">rm</span> ASTGTM_dem.tif
&nbsp;
gdalwarp   <span class="re5">-tr</span> <span class="nu0">25.0</span> <span class="nu0">25.0</span> -t_srs EPSG:<span class="nu0">32632</span>  -s_srs EPSG:<span class="nu0">4326</span>  ~<span class="sy0">/</span>Ndata<span class="sy0">/</span>ASTGTM<span class="sy0">/*/</span>AST<span class="sy0">*</span>dem.tif ASTGTM_dem.tif
&nbsp;
g.mapset PERMANENT
&nbsp;
r.in.gdal <span class="re2">in</span>=ASTGTM_dem.tif <span class="re2">out</span>=ASTGTM_dem <span class="re5">--overwrite</span>
&nbsp;
g.region <span class="re2">vect</span>=AdminOmrader_pol<span class="sy0">@</span>Combined <span class="re2">nsres</span>=<span class="nu0">25</span> <span class="re2">ewres</span>=<span class="nu0">25</span> <span class="re5">-sp</span> <span class="co0">##change the default region extent and resolution</span>
&nbsp;
r.mapcalc <span class="re2">Elev_dem</span>=ASTGTM_dem
&nbsp;
&nbsp;
&nbsp;
g.mapset Combined
g.copy <span class="re2">rast</span>=Elev_dem<span class="sy0">@</span>PERMANENT,Elev_dem
&nbsp;
g.mapset PERMANENT
g.remove <span class="re2">rast</span>=Elev_dem
<span class="co0">###############################################################################</span>
&nbsp;
<span class="co0">###############################################################################</span></pre>

<p>
<br/>

</p>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;GRASS&quot;,&quot;hid&quot;:&quot;grass&quot;,&quot;codeblockOffset&quot;:0,&quot;secid&quot;:13,&quot;range&quot;:&quot;4481-8374&quot;} -->
<h3 class="sectionedit14" id="r">R</h3>
<div class="level3">
<pre class="code r">####################################################################################
&nbsp;
###################################################
# Import the habitat quality data
# In the habitat data file I received, the different land use types had a separate column. Here I combine them into one column. 
###################################################
setwd(&quot;~/Till AD!/GIS-Norge/R/&quot;)
habitat&lt;-read.table(&quot;../Sandra-data/habitat.txt&quot;,header=T)
habitat$hab[habitat$open.forest==1]&lt;-&quot;open.forest&quot;
habitat$hab[habitat$open.grass==1]&lt;-&quot;open.grass&quot;
habitat$hab[habitat$wetlands==1]&lt;-&quot;wetlands&quot;
habitat&lt;-within(habitat,rm(list=c(&quot;open.forest&quot;,&quot;open.grass&quot;,&quot;wetlands&quot;)))
&nbsp;
##################################################################################
&nbsp;
&nbsp;
&nbsp;
##################################################################################
&nbsp;
##################################################
# Import the transects
##################################################
## A bit confusingely, the &quot;label&quot; categories does not mean the same thing in the bumblebee&amp;butterfly data as in the transects. 
## This is because those were visited three times but I only have transect data for one time (because the places does not move between visit time)
## Therefore I have to fix this. This code is just to fix the pequliarities of my data set
## This has to be run in GRASS===&gt;&gt;R
##################################################
library(spgrass6)
load(&quot;~/Ndata/transects.rdata&quot;)
&nbsp;
transects$odd&lt;-rep(c(1,0),nrow(transects)/2)
##Get rid of the end points of the transects! (both start and end points were recorded, start point will define the location of the transects)
transects&lt;-subset(transects,transects$odd==1) 
rownames(transects@data)&lt;-1:nrow(transects) ##Update rownames to avoid future confusion
##This next bit will split the labels, multiply everything 3 times, add the 3 time codes and finally reassemble tha labels. 
##Another option would have been to do this at the start, before matching the positions with explanatory data in GRASS
&nbsp;
transects$label&lt;-as.character(transects$label)
splitted&lt;-matrix(unlist(strsplit(transects$label,&quot;-&quot;)),nrow=nrow(transects),byrow=T)
transects$square&lt;-splitted[,1]
transects$corner&lt;-splitted[,2]
transects$transect&lt;-splitted[,3]
transects&lt;-rbind(transects,transects,transects) ##Create 3 copies, now the row numbers match with the inventory data
transects$period&lt;-rep(1:3,each=nrow(transects)/3)
transects@data$label&lt;-paste(transects@data[,&quot;square&quot;],transects@data[,&quot;period&quot;],transects@data[,&quot;corner&quot;],transects@data[,&quot;transect&quot;],sep=&quot;-&quot;)
transects&lt;-transects[,c(&quot;label&quot;,&quot;Arealdekke&quot;,&quot;Elev&quot;)]
transects$label&lt;-as.character(transects$label)
&nbsp;
##############################################################################################################
&nbsp;
&nbsp;
&nbsp;
##############################################################################################################
&nbsp;
###################################################
# Import and set up the bumblebee data
###################################################
&nbsp;
setwd(&quot;~/Till AD!/GIS-Norge/R/&quot;)
bumble&lt;-read.table(&quot;../Sandra-data/humlor.txt&quot;,header=T)
#str(bumble)
temp&lt;-bumble[,7:58] ##Subsample only the species column for further manipulation
all.names&lt;-gsub(&quot;(^B\\.[a-z]*)(\\..)&quot;,&quot;\\1&quot;,names(temp)) ##Remove trailing letters indicating caste and sex of individuals
unique.names&lt;-unique(all.names) ##With caste and sex info taken away, we have multiple occurrences of same name. Take only 1 of each
new&lt;-data.frame(matrix(nrow=nrow(temp),ncol=length(unique.names)))##Make an empty temporary data frame 
names(new)&lt;-unique.names ##Assign names, and fill it with the summed abundances at species level. This will contain all the correct abundance data
for(i in 1:length(unique.names)){
new[,i]&lt;-rowSums(temp[all.names==unique.names[i]])
}
bumble&lt;-within(bumble,rm(list=c(names(bumble)[7:58]))) ##Get rid of old data
bumble&lt;-cbind(bumble,new) ##replace with new data (at species level)
rm(temp) ##A little housekeeping
rm(new)
bumble$spec.rich&lt;-rowSums(bumble[,8:22]&gt;0) ##Create a new column for species richness
bumble&lt;-merge(habitat,bumble) ##Merge the habitat quality data frame with the inventory results,  and set the appropriate explanatory variables as factors
for(i in 1:7){
bumble[,i]&lt;-as.factor(bumble[,i])
}
##Add combined transect ID string for future merging with transect location data
bumble$label&lt;-paste(bumble[,&quot;square&quot;],bumble[,&quot;period&quot;],bumble[,&quot;corner&quot;],bumble[,&quot;transect&quot;],sep=&quot;-&quot;) 
bumble&lt;-merge(transects,bumble)
bumble$flower.cov&lt;-as.numeric(bumble$flower.cov) ##Set the flower cover variable as numeric (Can be questioned, maybe it is a ordinal category?)
&nbsp;
&nbsp;
##################################################################################
&nbsp;
#####################################################################################################################
&nbsp;
###################################################
# Reshaping data
# THIS bit is not necessary when working on all of the data, only when I want to aggregate on some level, e.g. period.
# I include the code anyhow, since reshape is very useful.The point is to aggregate the data at some level.
# For example aggregate data censored at the village level to county or region level.
###################################################
&nbsp;
bumble.melt&lt;-melt(bumble,c(1:13))
bumble&lt;-cast(bumble.melt,formula=square+period+corner+transect+Sandra.JanOve+hab+flower.cov+Arealdekke+Elev~variable,sum)
&nbsp;
#####################################################################################################################</pre>

<p>
<br/>

</p>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;R&quot;,&quot;hid&quot;:&quot;r&quot;,&quot;codeblockOffset&quot;:1,&quot;secid&quot;:14,&quot;range&quot;:&quot;8375-13987&quot;} -->
<h2 class="sectionedit15" id="get_new_information_out_of_grass">Get new information out of GRASS</h2>
<div class="level2">
<pre class="code">#!/bin/bash
#
#
#	This script queries the Land cover layer and the Elevation layer for their information at the locations of the visited transects.
#
#	This information will be used to model the results of the inventory.
#
#
#
#
#

g.mapset Combined
g.region -dp

#g.copy vect=transects_pnt@PERMANENT,transects_pnt

v.db.addcol transects_pnt col=&quot;Arealdekke varchar(20)&quot;
v.what.vect transects_pnt qvector=Arealdekke_pol qcolumn=OBJTYPE col=Arealdekke

#v.db.select transects_pnt columns=Arealdekke

v.db.addcol transects_pnt col=&quot;Elev integer&quot;

v.what.rast vector=transects_pnt raster=Elev_dem layer=1 column=Elev

##########################################################################
#
#
#	This script export/imports the vector layer &quot;transects_pnt&quot; (with the added information in it) into R
#
#
#
#
#
#
#


R

library(&quot;spgrass6&quot;)

transects&lt;-readVECT6(&quot;transects_pnt&quot;)

## A little housekeeping, fixing the character encoding errors

transects$Arealdekke&lt;-as.character(transects$Arealdekke)

transects@data$Arealdekke[transects@data$Arealdekke==&quot;\xc5pentOmr\xe5de&quot;]&lt;-&quot;OpentOmrade&quot;
transects@data$Arealdekke[transects@data$Arealdekke==&quot;Industriomr\xe5de&quot;]&lt;-&quot;Industriomr&quot;

## One of the visited places was located ~ 100 metres outside of the region I had GIS layers of.
## Looking at google maps, I could see that the land type was Forest = Skog

transects$Arealdekke[which(is.na(transects@data$Arealdekke))]&lt;-&quot;Skog&quot; 
transects$Arealdekke&lt;-as.factor(transects$Arealdekke)

save(file=&quot;~/Ndata/transects.rdata&quot;,transects)

###############################################################################
 
</pre>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;Get new information out of GRASS&quot;,&quot;hid&quot;:&quot;get_new_information_out_of_grass&quot;,&quot;codeblockOffset&quot;:2,&quot;secid&quot;:15,&quot;range&quot;:&quot;13988-15659&quot;} -->
<h2 class="sectionedit16" id="modelling">Modelling</h2>
<div class="level2">

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;Modelling&quot;,&quot;hid&quot;:&quot;modelling&quot;,&quot;codeblockOffset&quot;:3,&quot;secid&quot;:16,&quot;range&quot;:&quot;15660-15682&quot;} -->
<h3 class="sectionedit17" id="in_r_glm">IN R (GLM)</h3>
<div class="level3">
<pre class="code r">calib3&lt;-glm(tot.huml~Arealdekke+Elev,data=bumble,family=poisson) ##Simplistic GLM to predict from</pre>

<p>
<br/>

</p>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;IN R (GLM)&quot;,&quot;hid&quot;:&quot;in_r_glm&quot;,&quot;codeblockOffset&quot;:3,&quot;secid&quot;:17,&quot;range&quot;:&quot;15683-15823&quot;} -->
<h3 class="sectionedit18" id="in_jags_bayesian_version_of_glm">IN JAGS (Bayesian version of GLM)</h3>
<div class="level3">
<pre class="code r">#################################################
### Bayesian version of the simple GLM model
#################################################
&nbsp;
##This script will produce a Bayesian version of the simple GLM I did earlier.
##The result will be that the uncertainty in all the parameter estimations will be taken into account
## when estimating each parameter. This will result in wider confidence bounds for the parameters (which can
## be said to better represent our unceartainty about the system)
##
##
## Finally, I will not just use the best estimate of all the parameters in the GLM for the predictions, but instead take random draws
## from the posterior distribution of these parameters. One set of parameter draws will be used to create one prediction about the system.
## Then, I will take another draw and repeat the process, resulting in many realized predictions.
## Most of the parameter random draws will lie close to the best estimate, but I will allow for the fact
## that I don't have absolute knowledge about the exact value of these parameters (or if you like, that there is no single &quot;true&quot; value)
##
## With this set of predictions, I can then visualize the uncertainty, calculate variation of predictions for each pixel or the whole map, sort them and display the 2.5 and 97.5 % quantiles 
## to create &quot;credable confidence bounds&quot; on the maps
&nbsp;
##First load the &quot;rjags&quot; package
&nbsp;
library(rjags) ##This will make R and JAGS talk to each other
load.module(&quot;glm&quot;) ##This is a JAGS module that is good to use when modelling GLM like models
&nbsp;
##Set up the model in JAGS (The actual model is in the text file, shown a bit later below)
Bayesian.glm&lt;-jags.model(&quot;~/scripts/glm1.txt&quot;,data=bumble,n.chains=3)
update(Bayesian.glm,1000) ## Burn in period for the Marcov chains
&nbsp;
## Get samples of the MCMC chains. Specify wich parameters to &quot;collect&quot; 10 000 updates and collect only every 50th to combat autocorrelation
B.out&lt;-coda.samples(Bayesian.glm,c(&quot;intercept&quot;,&quot;dekke&quot;,&quot;elev.par&quot;),n.iter=10000,thin=50) 
&nbsp;
gelman.diag(B.out[,2:8]) # Check convergence of chains</pre>

</div>

<h4 id="and_here_is_the_actual_bugs_jags_model">And here is the actual BUGS/JAGS model</h4>
<div class="level4">
<pre class="code">model{

for(i in 1:length(tot.huml)){

      tot.huml[i]~dpois(est[i])
      log(est[i])&lt;-intercept+dekke[Arealdekke[i]]+elev.par*Elev[i]
      
      }
      
      dekke[1]&lt;-0
      for(j in 2:6){
	  dekke[j]~dnorm(0.0,1.0E-6)
	  }
      intercept~dnorm(0.0,1.0E-6)
      elev.par~dnorm(0.0,1.0E-6)
      
}
      
  </pre>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;IN JAGS (Bayesian version of GLM)&quot;,&quot;hid&quot;:&quot;in_jags_bayesian_version_of_glm&quot;,&quot;codeblockOffset&quot;:4,&quot;secid&quot;:18,&quot;range&quot;:&quot;15824-18347&quot;} -->
<h2 class="sectionedit19" id="prediction">Prediction</h2>
<div class="level2">

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;Prediction&quot;,&quot;hid&quot;:&quot;prediction&quot;,&quot;codeblockOffset&quot;:6,&quot;secid&quot;:19,&quot;range&quot;:&quot;18348-18371&quot;} -->
<h3 class="sectionedit20" id="in_r">IN R</h3>
<div class="level3">

<p>
<br/>

</p>
<pre class="code r">#################################################
&nbsp;
#!/bin/bash
#
#	This script copies all the vectors in the PERMANENT mapset starting with Eidsberg to the new location Eidberg.
#	This subregion will be the target for prediction since predicting on the whole data set at 25 meters resolution 
#	turned out to be too much for my computer
#
#
#
&nbsp;
g.mapset -c Eidsberg
&nbsp;
for file in Eidsberg_AdminOmrader_lin Eidsberg_AdminOmrader_pol Eidsberg_Arealdekke_lin Eidsberg_Arealdekke_pnt Eidsberg_Arealdekke_pol Eidsberg_ByggOgAnlegg_lin Eidsberg_ByggOgAnlegg_pnt Eidsberg_ByggOgAnlegg_pol Eidsberg_Hoyde_lin Eidsberg_Hoyde_pnt Eidsberg_RestriksjonsOmrader_lin Eidsberg_RestriksjonsOmrader_pol Eidsberg_Samferdsel_lin Eidsberg_Samferdsel_pnt    
do
&nbsp;
g.copy vect=$file@PERMANENT,$file
&nbsp;
done
&nbsp;
##########################################################################
&nbsp;
&nbsp;
&nbsp;
################################################################################################################
#
#
#   This script first changes the land use types to numeric codes. 
#   Then it creates a raster of the land use information to get values at every pixel.
#   Then it fits a simple GLM to the data, using the newly acquired information as explanatory variables.
#   As an example, I will use the total abundance of Bumblebees.
#
#
#
&nbsp;
&nbsp;
R
&nbsp;
library(spgrass6)
##This is the corresponding codes for the land use types. I have to use numbers in the models later
&nbsp;
#1 Alpinbakke
#2 BymessigBebyggelse
#3 DyrketMark
#4 ElvBekk
#5 FerskvannTorrfall
#6 Golfbane
#7 Gravplass
#8 Havflate
#9 Industriomrade
#10 Innsjo
#11 Lufthavn
#12 Myr
#13 Park
#14 OpentOmrade
#15 Skog
#16 SportIdrettPlass
#17 Steinbrudd
#18 Steintipp
#19 TettBebyggelse
&nbsp;
##It turned out to be a bit of a chore changing the land use names to numbers in GRASS, so I did it in R in stead
&nbsp;
&nbsp;
areal&lt;-readVECT6(&quot;Arealdekke_num&quot;) ##Import the vector into R
areal@data$NR&lt;-as.numeric(areal@data$OBJTYPE) #change it to numeric,easy-peasy
writeVECT6(areal,&quot;areal_num&quot;) ##Export it again to GRASS
&nbsp;
##  Then make a raster out of it to get the information on a pixel level
system(&quot;v.to.rast input=areal_num@Combined output=arealdekke_num use=attr type=point,line,area layer=1 column=NR value=1 rows=4096 &quot;) ##Call grass with &quot;system&quot;
&nbsp;
&nbsp;
system(&quot;g.mapset Eidsberg&quot;) ## Make sure you have the correct mapset
areal&lt;-readRAST6(&quot;Arealdekke_eid&quot;) ##This is the land use information
gc() ##This clean the memory of garbage, makes you computer happy. Useful when handling large files
elev&lt;-readRAST6(&quot;Elev_dem_eid&quot;) ## This is the elevation information, already in raster format
gc()
&nbsp;
pred.frame&lt;-data.frame(c(areal@data,elev@data)) ##Make a data frame with both predictors to work on
names(pred.frame)&lt;-c(&quot;Arealdekke&quot;,&quot;Elev&quot;)
pred.frame$Arealdekke&lt;-factor(pred.frame$Arealdekke) ##Make it into a factor
gc()
&nbsp;
&nbsp;
pred.frame$Arealdekke&lt;-as.character(pred.frame$Arealdekke)
pred.frame$Arealdekke[is.na(pred.frame$Arealdekke)]&lt;-0 ##Weird things happen when you have NAs in the treatment categories. Replace them with zeroes
pred.frame$Arealdekke&lt;-as.factor(pred.frame$Arealdekke)
&nbsp;
##The next part is a bit complicated if you don't know the data. 
##It has to do with the fact that the are more land use categories in the new data set then the ones used for model calibration. 
##The following code is really ugly at some places
##First make a subset of the new region that only contains the land use types visited
temp&lt;-pred.frame[pred.frame$Arealdekke==3 | pred.frame$Arealdekke==9 | pred.frame$Arealdekke==12 | pred.frame$Arealdekke==14 | pred.frame$Arealdekke==15 | pred.frame$Arealdekke==19,]
bla&lt;-as.factor(as.character(temp$Arealdekke))
temp$Arealdekke&lt;-bla
rm(bla)
#table(temp$Arealdekke) 
&nbsp;
## Reclassify the land use types visited when inventoring to numbers
bumble$Arealdekke&lt;-as.character(bumble$Arealdekke)
bumble$Arealdekke[bumble$Arealdekke==&quot;DyrketMark&quot;]&lt;-&quot;3&quot;
bumble$Arealdekke[bumble$Arealdekke==&quot;Gravplass&quot;]&lt;-&quot;7&quot;
bumble$Arealdekke[bumble$Arealdekke==&quot;Industriomr&quot;]&lt;-&quot;9&quot;
bumble$Arealdekke[bumble$Arealdekke==&quot;Myr&quot;]&lt;-&quot;12&quot;
bumble$Arealdekke[bumble$Arealdekke==&quot;OpentOmrade&quot;]&lt;-&quot;14&quot;
bumble$Arealdekke[bumble$Arealdekke==&quot;Skog&quot;]&lt;-&quot;15&quot;
bumble$Arealdekke[bumble$Arealdekke==&quot;TettBebyggelse&quot;]&lt;-&quot;19&quot;
bumble$Arealdekke&lt;-as.factor(bumble$Arealdekke)
&nbsp;
##Make a prediction based on a simplistic GLM
##
#pred.frame$predict&lt;-rep(0,nrow(pred.frame)) ##Make a new vector in the prediction data frame for the predictions. Areas without information will get value 0. This can be changed later
pred.frame$predict&lt;-rep(NA,nrow(pred.frame))
calib3&lt;-glm(tot.huml~Arealdekke+Elev,data=bumble,family=poisson) ##Simplistic GLM to predict from
predicted&lt;-predict(calib3,temp,type=&quot;response&quot;) ##New prediction
#pred.frame$predict&lt;-numeric(nrow(pred.frame))
##Fill the right slots with predictions
pred.frame$predict[pred.frame$Arealdekke==3 | pred.frame$Arealdekke==9 | pred.frame$Arealdekke==12 | pred.frame$Arealdekke==14 | pred.frame$Arealdekke==15 | pred.frame$Arealdekke==19]&lt;-predicted
elev$predicted&lt;-pred.frame$predict
## Prediction done!
## The prediction can then be transported to GRASS by: writeRAST6(elev,&quot;New_raster&quot;,zcol=&quot;predict&quot;,overwrite=T)
&nbsp;
###########################################################################################################################</pre>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;IN R&quot;,&quot;hid&quot;:&quot;in_r&quot;,&quot;codeblockOffset&quot;:6,&quot;secid&quot;:20,&quot;range&quot;:&quot;18372-23685&quot;} -->
<h3 class="sectionedit21" id="bayesian_model">Bayesian model</h3>
<div class="level3">
<pre class="code r">B.res&lt;-summary(B.out[,2:8])$statistics
B.est&lt;-B.res[,1]
&nbsp;
##Rearrange so that Intercept term is in the first slot
B.est&lt;-c(B.est[7],B.est[1:6])
&nbsp;
B.prediction&lt;-exp(model.matrix(glm(1:nrow(temp)~Arealdekke+Elev,data=temp)) %*% B.est) ##This is where the prediction is made. Similar function as predict() function
&nbsp;
cor.test(temp$B.pred,temp$predict) ##Correlation between the GLM (frequentist) estimate and the Bayesian estimate == 92%
&nbsp;
&nbsp;
################WRITE THE BAYESIAN PREDICTION###############
pred.frame$predict&lt;-rep(NA,nrow(pred.frame)) ##Fill it with NAs. This is replaced by predicted values next.
pred.frame$predict[pred.frame$Arealdekke==3 | pred.frame$Arealdekke==9 | pred.frame$Arealdekke==12 | pred.frame$Arealdekke==14 | pred.frame$Arealdekke==15 | pred.frame$Arealdekke==19]&lt;-B.prediction
elev$B.pred&lt;-pred.frame$predict
&nbsp;
##Done!
##
&nbsp;
##################################################################################
&nbsp;
&nbsp;
#####RANDOM DRAWS FROM POSTERIOR PARAMETER DISTRIBUTIONS##############
&nbsp;
&nbsp;
&nbsp;
##The function B.new draws random numbers from the output of the Bayesian analysis, by simply sampling the Coda outputs. This way, I can only draw numbers that were actually produced by JAGS.
## Another way would be to define a distribution from the estimated standard errors from the output. Then I would be able to draw any number from the distribution. 
&nbsp;
B.new&lt;-function(){
temp&lt;-c(sample(size=1,unlist(B.out[,8])),sample(size=1,unlist(B.out[,2])),sample(size=1,unlist(B.out[,3])),sample(size=1,unlist(B.out[,4])),sample(size=1,unlist(B.out[,5])),sample(size=1,unlist(B.out[,6])),sample(size=1,unlist(B.out[,7])))
return(temp)
}
&nbsp;
################################################################################</pre>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;Bayesian model&quot;,&quot;hid&quot;:&quot;bayesian_model&quot;,&quot;codeblockOffset&quot;:7,&quot;secid&quot;:21,&quot;range&quot;:&quot;23686-25448&quot;} -->
<h3 class="sectionedit22" id="let_s_make_a_movie">Let&#039;s make a movie</h3>
<div class="level3">
<pre class="code r">##################################################
###make movie, Bayesian random parameter draw version
##################################################
setwd(&quot;/home/astrom/Till AD!/GIS-Norge/out&quot;)
#system(&quot;g.region rows=1080 cols=1280 -p&quot;)
system(&quot;g.region rows=1412 cols=1670 -p&quot;)
#system(&quot;g.region rast=Elev_dem_eid -p&quot;)
&nbsp;
&nbsp;
for(i in 1:50){
B.prediction&lt;-exp(model.matrix(glm(1:nrow(temp)~Arealdekke+Elev,data=temp)) %*% B.new()) ##Multiply the model matrix with the random drawn parameters
pred.frame$predict&lt;-numeric(nrow(pred.frame))
pred.frame$predict[pred.frame$Arealdekke==3 | pred.frame$Arealdekke==9 | pred.frame$Arealdekke==12 | pred.frame$Arealdekke==14 | pred.frame$Arealdekke==15 | pred.frame$Arealdekke==19]&lt;-B.prediction
elev$B.pred&lt;-pred.frame$predict
&nbsp;
elev$B.rand.pois&lt;-rpois(nrow(elev),elev$B.pred) ##Pick one random draw from the estimated mean in each pixel
&nbsp;
writeRAST6(elev,paste(&quot;pois&quot;,i,sep=&quot;&quot;),zcol=&quot;B.rand.pois&quot;,overwrite=T)
}
system(&quot;for i in `seq 1 50` 
 do
  r.out.png input=pois$i output=pois$i
   g.remove rast=pois$i 
    done&quot;)
&nbsp;
system(&quot;convert -delay 20 *.png 1670B-rand-pois.mpg&quot;)
&nbsp;
&nbsp;
##############################################################</pre>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;Let&#039;s make a movie&quot;,&quot;hid&quot;:&quot;let_s_make_a_movie&quot;,&quot;codeblockOffset&quot;:8,&quot;secid&quot;:22,&quot;range&quot;:&quot;25449-26678&quot;} -->
<h3 class="sectionedit23" id="validation">Validation</h3>
<div class="level3">

<p>
I won&#039;t make any attempts at validating my models. I already know they are extremely simplistic and will not have much explanatory power. One predictor that seems to be important is Flower cover, but I don&#039;t have data for that other than at the visited sites. Interpolating these values might be a possible road but I won&#039;t look into that now.
</p>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;Validation&quot;,&quot;hid&quot;:&quot;validation&quot;,&quot;codeblockOffset&quot;:9,&quot;secid&quot;:23,&quot;range&quot;:&quot;26679-27044&quot;} -->
<h2 class="sectionedit24" id="results_and_discussion">RESULTS and DISCUSSION</h2>
<div class="level2">
<ol>
<li class="level1"><div class="li"> The first picture shows the prediction from the GLM model. White areas are those with land uses the inventory personnel did not visit, so I won&#039;t predict to those areas.</div>
</li>
<li class="level1"><div class="li"> The second picture shows the corresponding output for the Bayesian analysis. The parameter values changes slightly which creates a pretty large change in the colormapping.</div>
</li>
<li class="level1"><div class="li"> The third picture shows the best estimate frequentistic GLM (1) prediction but for one random outcome. That is I draw a random number from a Poisson dist with the prediction as mean.</div>
</li>
<li class="level1"><div class="li"> The third picture/movie show 10 possible outcomes when you let the parameter values vary randomly according to the uncertainty in the Bayesian estimation, plus random noise as in (3). You can make a longer movie as well with better resolution but it won&#039;t fit in this wiki-page </div>
</li>
</ol>
<ol>
<li class="level1"><div class="li"> The fourth plot shows a diagnostic plot of the Bayesian estimation. The MCMC chains seems to have converged well, and the parameter distributions look reasonable.</div>
</li>
</ol>

<p>
<br/>

<a href="/dokuwiki/lib/exe/detail.php?id=wikidk%3Adk10mbee&amp;media=wikidk:f_pred_na.png" class="media" title="wikidk:f_pred_na.png"><img src="/dokuwiki/lib/exe/fetch.php?w=400&amp;tok=ea6b7b&amp;media=wikidk:f_pred_na.png" class="media" title="Frequentist prediction, best estimate" alt="Frequentist prediction, best estimate" width="400" /></a>
<a href="/dokuwiki/lib/exe/detail.php?id=wikidk%3Adk10mbee&amp;media=wikidk:b_pred_na.png" class="media" title="wikidk:b_pred_na.png"><img src="/dokuwiki/lib/exe/fetch.php?w=400&amp;tok=b3dc4b&amp;media=wikidk:b_pred_na.png" class="media" title="Bayesian prediction, best estimate" alt="Bayesian prediction, best estimate" width="400" /></a>
<a href="/dokuwiki/lib/exe/detail.php?id=wikidk%3Adk10mbee&amp;media=wikidk:f_pred_pois_na_small.png" class="media" title="wikidk:f_pred_pois_na_small.png"><img src="/dokuwiki/lib/exe/fetch.php?w=400&amp;tok=d99dfc&amp;media=wikidk:f_pred_pois_na_small.png" class="media" title="Frequentist prediction, best estimate + poisson random draws" alt="Frequentist prediction, best estimate + poisson random draws" width="400" /></a>
<a href="/dokuwiki/lib/exe/detail.php?id=wikidk%3Adk10mbee&amp;media=wikidk:b_par_pois_na.gif" class="media" title="wikidk:b_par_pois_na.gif"><img src="/dokuwiki/lib/exe/fetch.php?media=wikidk:b_par_pois_na.gif" class="media" title="10 random outcomes of bumblebees. Random parameter draws + poisson random draws. Bigger movie is problematic on wiki" alt="10 random outcomes of bumblebees. Random parameter draws + poisson random draws. Bigger movie is problematic on wiki" /></a>
<a href="/dokuwiki/lib/exe/detail.php?id=wikidk%3Adk10mbee&amp;media=wikidk:mcmcplot.png" class="media" title="wikidk:mcmcplot.png"><img src="/dokuwiki/lib/exe/fetch.php?w=400&amp;tok=c6f447&amp;media=wikidk:mcmcplot.png" class="media" title="Diagnostic plot of the MCMC sampling" alt="Diagnostic plot of the MCMC sampling" width="400" /></a>
<br/>

</p>

</div>
<!-- EDIT{&quot;target&quot;:&quot;section&quot;,&quot;name&quot;:&quot;RESULTS and DISCUSSION&quot;,&quot;hid&quot;:&quot;results_and_discussion&quot;,&quot;codeblockOffset&quot;:9,&quot;secid&quot;:24,&quot;range&quot;:&quot;27045-&quot;} -->